{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the csv"
      ],
      "metadata": {
        "id": "lrOuQxl3a9hf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_Ff8LwCX8mu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functiom to add random noise"
      ],
      "metadata": {
        "id": "xNF5l89VbQM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_noise(image):\n",
        "    # Convert image to numpy array\n",
        "    img = np.array(image)\n",
        "    # Generate random noise\n",
        "    noise = np.random.randint(0, 255, img.shape)\n",
        "    # Add noise to image\n",
        "    noisy_image = np.clip(img + noise, 0, 255).astype(np.uint8)\n",
        "    # Convert back to PIL Image\n",
        "    return Image.fromarray(noisy_image)"
      ],
      "metadata": {
        "id": "gsqOd7t1bCF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the older csv and create a new csv"
      ],
      "metadata": {
        "id": "CRW48PjMbLfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the original CSV file\n",
        "csv_path = '/content/drive/MyDrive/RAFdb/fer2013.csv'\n",
        "\n",
        "# Path to the new CSV file\n",
        "new_csv_path = '/content/drive/MyDrive/RAFdb/fer2013Augmented.csv'"
      ],
      "metadata": {
        "id": "bfQrgyoHbUa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the dataframe"
      ],
      "metadata": {
        "id": "6nfwmXy0bdG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the original CSV file into a DataFrame\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Create a new DataFrame for the noisy images\n",
        "noisy_df = pd.DataFrame(columns=df.columns)\n"
      ],
      "metadata": {
        "id": "qI1JxTCHbfbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function to add noise"
      ],
      "metadata": {
        "id": "OmS7zaFHce2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df)):\n",
        "    # Load the image from the pixel values in the CSV file\n",
        "    pixels = df.loc[i, 'pixels'].split()\n",
        "    pixels = [int(p) for p in pixels]\n",
        "    image = Image.fromarray(np.uint8(np.array(pixels).reshape(48,48)))\n",
        "    # Add noise to the image\n",
        "    noisy_image = add_noise(image)\n",
        "    # Convert the noisy image back to pixel values and update the row\n",
        "    noisy_pixels = np.array(noisy_image).reshape(-1).tolist()\n",
        "    df.loc[i, 'pixels'] = ' '.join([str(p) for p in noisy_pixels])\n",
        "    # Add the updated row to the new DataFrame\n",
        "    noisy_df = noisy_df.append(df.loc[i])"
      ],
      "metadata": {
        "id": "bUm8Gatbchs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save new images"
      ],
      "metadata": {
        "id": "QP3W7VYqdHsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_df.to_csv(new_csv_path, index=False)"
      ],
      "metadata": {
        "id": "iM1GlSgRdJrm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "8baebff4-fe3a-4a58-ded0-41b256cef564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-cbcfa566ee2a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnoisy_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_csv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'noisy_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display first twenty"
      ],
      "metadata": {
        "id": "ys86KdkZdw7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_first_20(df, title):\n",
        "    fig, axs = plt.subplots(4, 5, figsize=(10, 10))\n",
        "    for i in range(20):\n",
        "        pixels = df.loc[i, 'pixels'].split()\n",
        "        pixels = [int(p) for p in pixels]\n",
        "        image = Image.fromarray(np.uint8(np.array(pixels).reshape(48,48)))\n",
        "        row = i // 5\n",
        "        col = i % 5\n",
        "        axs[row, col].imshow(image, cmap='gray')\n",
        "        axs[row, col].axis('off')\n",
        "        axs[row, col].set_title(df.loc[i, 'emotion'])\n",
        "    plt.suptitle(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "X0PRaKpUdy-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 20 images from the original CSV\n",
        "display_first_20( df, 'Original Images')\n"
      ],
      "metadata": {
        "id": "B1hj8P-td4AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 20 images from the new CSV\n",
        "display_first_20(noisy_df, 'Noisy Images')"
      ],
      "metadata": {
        "id": "bn4tenRZeHcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "OvZgqklYgcpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On OG data set."
      ],
      "metadata": {
        "id": "FjpJBrewghGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_df = pd.read_csv(new_csv_path)"
      ],
      "metadata": {
        "id": "xzxlDNmAp4Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_images(images):\n",
        "    images = np.array([np.fromstring(image, dtype=int, sep=' ').reshape(48, 48) for image in images])\n",
        "    images = np.expand_dims(images, axis=-1)\n",
        "    images = images / 255.0\n",
        "    return images"
      ],
      "metadata": {
        "id": "t6ipx4Jbgr1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function to train and test"
      ],
      "metadata": {
        "id": "qIjkR00FhunN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(data):\n",
        "    # Preprocess the images and labels\n",
        "    images = data['pixels']\n",
        "    labels = data['emotion']\n",
        "    images = preprocess_images(images)\n",
        "    \n",
        "    # Split the data into train/validation/test sets\n",
        "    X_train_val, X_test, y_train_val, y_test = train_test_split(images, labels, test_size=0.1, random_state=42)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.22, random_state=42)\n",
        "    \n",
        "    # Define the model architecture\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(7, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=25)\n",
        "    \n",
        "    # Evaluate the model on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "2a7rDfy2hpns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(noisy_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFNX6SD0qkwC",
        "outputId": "85865bad-d276-4232-f0dd-4f6e443400b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "788/788 [==============================] - 17s 7ms/step - loss: 1.7497 - accuracy: 0.2855 - val_loss: 1.6416 - val_accuracy: 0.3624\n",
            "Epoch 2/25\n",
            "788/788 [==============================] - 5s 6ms/step - loss: 1.6235 - accuracy: 0.3634 - val_loss: 1.5744 - val_accuracy: 0.3918\n",
            "Epoch 3/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 1.5670 - accuracy: 0.3891 - val_loss: 1.5561 - val_accuracy: 0.3988\n",
            "Epoch 4/25\n",
            "788/788 [==============================] - 5s 6ms/step - loss: 1.5206 - accuracy: 0.4082 - val_loss: 1.5130 - val_accuracy: 0.4074\n",
            "Epoch 5/25\n",
            "788/788 [==============================] - 5s 6ms/step - loss: 1.4777 - accuracy: 0.4281 - val_loss: 1.5038 - val_accuracy: 0.4213\n",
            "Epoch 6/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 1.4340 - accuracy: 0.4424 - val_loss: 1.5030 - val_accuracy: 0.4229\n",
            "Epoch 7/25\n",
            "788/788 [==============================] - 5s 6ms/step - loss: 1.3932 - accuracy: 0.4632 - val_loss: 1.4989 - val_accuracy: 0.4237\n",
            "Epoch 8/25\n",
            "788/788 [==============================] - 5s 6ms/step - loss: 1.3498 - accuracy: 0.4802 - val_loss: 1.5058 - val_accuracy: 0.4229\n",
            "Epoch 9/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 1.2974 - accuracy: 0.5007 - val_loss: 1.5096 - val_accuracy: 0.4229\n",
            "Epoch 10/25\n",
            "788/788 [==============================] - 5s 6ms/step - loss: 1.2480 - accuracy: 0.5231 - val_loss: 1.5188 - val_accuracy: 0.4289\n",
            "Epoch 11/25\n",
            "788/788 [==============================] - 5s 6ms/step - loss: 1.1991 - accuracy: 0.5448 - val_loss: 1.5445 - val_accuracy: 0.4127\n",
            "Epoch 12/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 1.1489 - accuracy: 0.5673 - val_loss: 1.6078 - val_accuracy: 0.4258\n",
            "Epoch 13/25\n",
            "788/788 [==============================] - 7s 9ms/step - loss: 1.0982 - accuracy: 0.5859 - val_loss: 1.6636 - val_accuracy: 0.4133\n",
            "Epoch 14/25\n",
            "788/788 [==============================] - 5s 6ms/step - loss: 1.0441 - accuracy: 0.6064 - val_loss: 1.7068 - val_accuracy: 0.4195\n",
            "Epoch 15/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.9931 - accuracy: 0.6285 - val_loss: 1.7196 - val_accuracy: 0.4140\n",
            "Epoch 16/25\n",
            "788/788 [==============================] - 6s 7ms/step - loss: 0.9420 - accuracy: 0.6480 - val_loss: 1.8312 - val_accuracy: 0.4109\n",
            "Epoch 17/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.8893 - accuracy: 0.6658 - val_loss: 1.9442 - val_accuracy: 0.3978\n",
            "Epoch 18/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.8379 - accuracy: 0.6902 - val_loss: 1.9942 - val_accuracy: 0.4122\n",
            "Epoch 19/25\n",
            "788/788 [==============================] - 5s 7ms/step - loss: 0.7877 - accuracy: 0.7111 - val_loss: 2.1391 - val_accuracy: 0.4039\n",
            "Epoch 20/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.7400 - accuracy: 0.7272 - val_loss: 2.1776 - val_accuracy: 0.3976\n",
            "Epoch 21/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.6949 - accuracy: 0.7437 - val_loss: 2.2845 - val_accuracy: 0.3902\n",
            "Epoch 22/25\n",
            "788/788 [==============================] - 5s 6ms/step - loss: 0.6501 - accuracy: 0.7601 - val_loss: 2.4896 - val_accuracy: 0.3904\n",
            "Epoch 23/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.6030 - accuracy: 0.7778 - val_loss: 2.5533 - val_accuracy: 0.3946\n",
            "Epoch 24/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.5609 - accuracy: 0.7958 - val_loss: 2.7561 - val_accuracy: 0.3926\n",
            "Epoch 25/25\n",
            "788/788 [==============================] - 5s 6ms/step - loss: 0.5278 - accuracy: 0.8081 - val_loss: 2.9399 - val_accuracy: 0.3957\n",
            "113/113 [==============================] - 0s 3ms/step\n",
            "Test accuracy: 0.3783783783783784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMgNPtYK22WG",
        "outputId": "9d6e1766-6091-4a6a-bded-9f4a4bd4a349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "788/788 [==============================] - 8s 7ms/step - loss: 1.6547 - accuracy: 0.3395 - val_loss: 1.4556 - val_accuracy: 0.4389\n",
            "Epoch 2/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 1.3956 - accuracy: 0.4637 - val_loss: 1.3061 - val_accuracy: 0.4976\n",
            "Epoch 3/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 1.2676 - accuracy: 0.5175 - val_loss: 1.2464 - val_accuracy: 0.5305\n",
            "Epoch 4/25\n",
            "788/788 [==============================] - 5s 6ms/step - loss: 1.1818 - accuracy: 0.5535 - val_loss: 1.2039 - val_accuracy: 0.5456\n",
            "Epoch 5/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 1.1049 - accuracy: 0.5831 - val_loss: 1.2296 - val_accuracy: 0.5467\n",
            "Epoch 6/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 1.0440 - accuracy: 0.6093 - val_loss: 1.1847 - val_accuracy: 0.5619\n",
            "Epoch 7/25\n",
            "788/788 [==============================] - 5s 7ms/step - loss: 0.9765 - accuracy: 0.6338 - val_loss: 1.1989 - val_accuracy: 0.5625\n",
            "Epoch 8/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.9130 - accuracy: 0.6616 - val_loss: 1.2189 - val_accuracy: 0.5636\n",
            "Epoch 9/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.8478 - accuracy: 0.6864 - val_loss: 1.2598 - val_accuracy: 0.5699\n",
            "Epoch 10/25\n",
            "788/788 [==============================] - 5s 7ms/step - loss: 0.7838 - accuracy: 0.7103 - val_loss: 1.3140 - val_accuracy: 0.5542\n",
            "Epoch 11/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.7165 - accuracy: 0.7361 - val_loss: 1.3092 - val_accuracy: 0.5660\n",
            "Epoch 12/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.6511 - accuracy: 0.7603 - val_loss: 1.3893 - val_accuracy: 0.5588\n",
            "Epoch 13/25\n",
            "788/788 [==============================] - 5s 6ms/step - loss: 0.5911 - accuracy: 0.7861 - val_loss: 1.4880 - val_accuracy: 0.5512\n",
            "Epoch 14/25\n",
            "788/788 [==============================] - 4s 6ms/step - loss: 0.5330 - accuracy: 0.8046 - val_loss: 1.5618 - val_accuracy: 0.5609\n",
            "Epoch 15/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.4764 - accuracy: 0.8276 - val_loss: 1.7116 - val_accuracy: 0.5581\n",
            "Epoch 16/25\n",
            "788/788 [==============================] - 5s 6ms/step - loss: 0.4247 - accuracy: 0.8458 - val_loss: 1.7745 - val_accuracy: 0.5567\n",
            "Epoch 17/25\n",
            "788/788 [==============================] - 5s 6ms/step - loss: 0.3833 - accuracy: 0.8606 - val_loss: 1.9378 - val_accuracy: 0.5512\n",
            "Epoch 18/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.3398 - accuracy: 0.8781 - val_loss: 2.1084 - val_accuracy: 0.5522\n",
            "Epoch 19/25\n",
            "788/788 [==============================] - 5s 7ms/step - loss: 0.3043 - accuracy: 0.8915 - val_loss: 2.2823 - val_accuracy: 0.5497\n",
            "Epoch 20/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.2783 - accuracy: 0.8989 - val_loss: 2.3057 - val_accuracy: 0.5519\n",
            "Epoch 21/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.2434 - accuracy: 0.9122 - val_loss: 2.4830 - val_accuracy: 0.5412\n",
            "Epoch 22/25\n",
            "788/788 [==============================] - 5s 7ms/step - loss: 0.2157 - accuracy: 0.9220 - val_loss: 2.6523 - val_accuracy: 0.5497\n",
            "Epoch 23/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.2126 - accuracy: 0.9262 - val_loss: 2.7738 - val_accuracy: 0.5387\n",
            "Epoch 24/25\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.1860 - accuracy: 0.9346 - val_loss: 2.9998 - val_accuracy: 0.5463\n",
            "Epoch 25/25\n",
            "788/788 [==============================] - 5s 7ms/step - loss: 0.1765 - accuracy: 0.9389 - val_loss: 3.0540 - val_accuracy: 0.5498\n",
            "113/113 [==============================] - 0s 2ms/step\n",
            "Test accuracy: 0.5252159375870716\n"
          ]
        }
      ]
    }
  ]
}